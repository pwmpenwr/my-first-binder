---
title: "Accessing an Excel dataset using SQL in R"
author: |
  | Pete Arnold
  | Swansea University Medical School
date: December 13<sup>th</sup>, 2018
output: html_notebook
---

As a first attempt, I have copied the XLSX file to a SQLite3 DB file using a Python function from Shahzeb Qureshi at https://stackoverflow.com/questions/17439885/export-data-from-excel-to-sqlite-database with the weak suggested by Zalakain.
It won't work with an exsiting DB file, so I have added a shell remove command to be executed before the python code.

I expect to tweak the python code to fix this and to prevent the error message about using TEXT with 'NoneType' entries which is due to the functioon attempting to read the empty second sheet.

Please remember to disconnect from the SQLite database when you have finished or this will cause an error if you try to delete again whilst it is still open.

```{sh}
# The connect function doesn't like working with an existing database (sheet already exists).
rm NeuronConnect.db
```
```{python}
'''
This code uses the openpyxl package for playing around with excel using Python code
to convert complete excel workbook (all sheets) to an SQLite database
The code assumes that the first row of every sheet is the column name
Every sheet is stored in a separate table
The sheet name is assigned as the table name for every sheet
'''

import sqlite3
import openpyxl
from openpyxl import load_workbook
import re

def slugify(text, lower=1):
    if lower == 1:
        text = text.strip().lower()
    text = re.sub(r'[^\w _-]+', '', text)
    text = re.sub(r'[- ]+', '_', text)
    return text

#Replace with a database name
con = sqlite3.connect(r'NeuronConnect.db')
#replace with the complete path to your excel workbook
wb = load_workbook(filename=r'NeuronConnect.xlsx')

sheets = wb.get_sheet_names()
#print(sheets)

for sheet in sheets:
    ws = wb[sheet] 

    columns= []
    query = 'CREATE TABLE ' + str(slugify(sheet)) + '(ID INTEGER PRIMARY KEY AUTOINCREMENT'
    for row in next(ws.rows):
        #print(row)
        query += ', ' + slugify(row.value) + ' TEXT'
        columns.append(slugify(row.value))
    query += ');'

    con.execute(query)

    tup = []
    for i, rows in enumerate(ws):
        tuprow = []
        if i == 0:
            continue
        for row in rows:
            tuprow.append(str(row.value).strip()) if str(row.value).strip() != 'None' else tuprow.append('')
        tup.append(tuple(tuprow))


    insQuery1 = 'INSERT INTO ' + str(slugify(sheet)) + '('
    insQuery2 = ''
    for col in columns:
        insQuery1 += col + ', '
        insQuery2 += '?, '
    insQuery1 = insQuery1[:-2] + ') VALUES('
    insQuery2 = insQuery2[:-2] + ')'
    insQuery = insQuery1 + insQuery2

    con.executemany(insQuery, tup)
    con.commit()

con.close()
```
```{r}
library(DBI)
db = dbConnect(RSQLite::SQLite(), dbname = "data/sql/NeuronConnect.db")
```
```{sql, connection=db}
SELECT * FROM Neurons

```
```{r}
dbDisconnect(db)
```

